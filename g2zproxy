#!/usr/bin/env python

### Dependencies: urllib, py-zabbix, yaml, json

import logging, logging.handlers
import sys, socket
import time
import urllib.request
import urllib.parse
import yaml
import json
import pprint
import collections.abc

from multiprocessing.pool import ThreadPool as Pool

try:
    import argparse
except:
    print("You need python 2.7+ or installed argparse module.\n\tpip install argparse")
    exit()

try:
    # from zabbix.api import ZabbixAPI
    from pyzabbix.api import ZabbixAPI
    # from zabbix.sender import ZabbixSender, ZabbixMetric
    from pyzabbix.sender import ZabbixSender, ZabbixMetric
except:
    print("Zabbix module py-zabbix is required.")
    exit()

logging.basicConfig(level = logging.DEBUG, format='%(asctime)s %(message)s', datefmt='%m/%d/%Y %I:%M:%S %p')
logger = logging.getLogger(__name__)

handler = logging.handlers.SysLogHandler(address='/dev/log',
                                         facility=logging.handlers.SysLogHandler.LOG_LOCAL0) #,
#                                         socktype=socket.SOCK_STREAM)
logger.addHandler(handler)

class JSONMetricsSorter(collections.abc.Mapping):
    """
    A class for objects which will track metrics on a per-host basis
    It will generate a JSON data packet for each host

    It stores everything as a hash, the keys being the hostnames.
    The values are hashes, mapping the Zabbix item key onto a value;
      a timestamp will be applied to the JSON payload.  It is problematic to do better.

    """
    # initialization function allows for override of metric name
    def __init__(self, *hostnames, **kwargs):
        self.metric_key = kwargs.get('metric_key', 'imported_metrics')
        self.data = {}
        if len(hostnames) > 0:
            for name in hostnames:
                self.data[name] = {}

    # provide __repr__ for string representation -- f"" strings not available until v3.6
    def __repr__(self):
        return "{cn}: metric_key: {k} data: {d}".format(cn=self.__class__.__name__,k=self.metric_key,d=self.data)

    # Provide certain private definitions for Mapping conformance
    def __len__(self):
        return len(self.data)

    def __iter__(self):
        yield from self.data

    def __getitem__(self, host):
        return self.data[host]

    # access the metric key
    def get_zabbix_metric_key(self):
        return self.metric_key

    # return a single ZabbixMetric object for the named host
    def get_metrics_for(self, host):
        try:
            return ZabbixMetric( host, self.metric_key, json.dumps( self.data[host] ))
        except KeyError as e:
            raise(e)

    # return a list of ZabbixMetric objects, one for each host referenced
    def get_all_metrics(self):
        return [ ZabbixMetric( host, self.metric_key, json.dumps( metrics )) for host,metrics in self.data.items() ]

    # insert another metric value for a particular host into the sorter
    def add_metric_for(self, host, keyname, value):
        if host not in self.data:
            self.data[host] = {}
        self.data[host][keyname] = value
        return self

class MetricsSorterByProxy(collections.abc.Mapping):
    """
    Creating a second class very similar to the previous class, this time to collect metrics on the
    basis of which proxy they need to go to, so that they can be sent only to proxies which know to
    expect metrics for the included hosts.

    """
    def __init__(self, *proxynames, **kwargs):
        self.data = {}
        if len(proxynames) > 0:
            for name in proxynames:
                self.data[name] = [] # we create a list for each proxy, of metrics which need to be sent

    # provide a representation
    def __repr__(self):
        return "{cn}: data: {d}".format(cn=self.__class__.__name__, d=self.data)

    # Provide certain private definitions for Mapping conformance
    def __len__(self):
        return len(self.data)

    def __iter__(self):
        yield from self.data

    def __getitem__(self, proxy):
        return self.data[proxy]

    def __not_imp_error(self):
        funcname = sys._getframe(1).f_code.co_name
        raise NotImplementedError('{} is not implemented by {}'.format(funcname, self.__class__.__name__))

    def get_all_metrics(self):
        self.__not_imp_error()

    def add_metric_for(self, host, keyname, value):
        self.__not_imp_error()

    def get_zabbix_metric_key(self, host, keyname, value):
        self.__not_imp_error()


    def add_metric(self, metric, keyname, value, time):
        if metric['proxy'] not in self.data:
            self.data[ metric['proxy'] ] = []
        self.data[ metric['proxy'] ].append( ZabbixMetric(metric['host'], keyname, value, time) )

    def get_metrics_for(self, proxy):
        return self.data[proxy]

    def get_proxies(self):
        return list(self.keys())


class G2ZProxyException(Exception):
    pass

class G2ZProxy(object):
    """
    Proxy between Graphite and Zabbix servers.

    Attributes:
        pattern (str)   Pattern for graphites key in zabbix.
                        Default: graphite*
    """

    def __init__(self, pattern='graphite*',
                 zabbix_url='http://localhost',
                 zabbix_user='admin',
                 zabbix_pass='zabbix',
                 zabbix_server=None,
                 zabbix_port=None,
                 graphite_url='http://localhost',
                 threads=1,
                 aggregation_function='{metric}',
                 hostname_munger=lambda x: x,
                 debug_mode=False):

        self.cn = self.__class__.__name__

        # Takes needed metric from zabbix
        self.pattern = pattern
        self.zabbix_url = zabbix_url
        self.graphite_url = graphite_url + '/render?from=-5minutes&rawData=true&target={req}&format=json'
        self.aggregation_function = aggregation_function
        self._getHostnameForGraphite = hostname_munger
        self.zapi = ZabbixAPI(self.zabbix_url, user=zabbix_user, password=zabbix_pass)
        self.threads = threads
        self.debug_mode = debug_mode
        self.proxy_sorter = MetricsSorterByProxy()
        if zabbix_server is not None:
            zabconf = { 'zabbix_server': zabbix_server }
            if zabbix_port is not None:
                zabconf['zabbix_port'] = zabbix_port
            self.zabbix_sender_config = lambda x: zabconf
        else:
            self.zabbix_sender_config = lambda x: x # we need to provide zabbix_server
        self._main()

    def _debugOutput(self, msg):
        logger.debug("{0}: outputting datastructure instead of sending to Zabbix".format(self.__class__.__name__))
        if len(msg) == 0:
            logger.debug(pprint.pformat(self.proxy_sorter))
        else:
            logger.debug(pprint.pformat(msg))

    def _getHostsFromMetrics(self, metrics):
        """
        Get list of unique hosts from metric list.

        Attributes:
          metrics (list)    List of metrics from zabbix
        """

        # Get list of uniq hostid
        hostids = list(set(map(lambda x: int(x['hostid']), metrics)))

        # Get host names by id
        hostids = self.zapi.host.get(hostids=hostids, output=['name', 'proxy_hostid'])

        # Get list of unique proxy ids
        proxies = list(set(map(lambda x: int(x['proxy_hostid']), hostids)))

        # Get list of proxy data
        proxies = self.zapi.proxy.get( proxyids=proxies, output=['proxy_address'] )

        # Map proxyid (string) onto its name, in order to create host->proxy mapping; no need to
        #   convert type as they are strings in both data structures
        proxymap = { p['proxyid']: p['proxy_address'] for p in proxies }

        hosts = {}
        for m in hostids: # we now pass back a dict w/ name and proxy keys as the value, instead of a string
            hosts.update({ int(m['hostid']): { 'name': m['name'], 'proxy': proxymap[m['proxy_hostid']] }  })

        logger.debug("{0}:_getHostsFromMetrics(metrics):{1}".format(self.__class__.__name__, hosts))

        return hosts

    def _getMonitoredMetrics(self):
        """
        Return monitored metrics from zabbix
        """

        result = None
        if self.zapi:
            metrics = self.zapi.item.get(
                search = { 'key_': self.pattern },
                searchWildcardsEnabled = True,
                monitored = True,
                output = ['key_', 'hostid'])
            result = metrics

        logger.debug("{0}:_getMonitoredMetrics(metrics):{1}".format(self.__class__.__name__, result))
        return result


    def _getMetrics(self):
        """
        Get metrics from zabbix transform it to list of key, value pairs.
        """

        result = None
        metrics = self._getMonitoredMetrics()
        hosts = self._getHostsFromMetrics(metrics) # { int(<hid>): { name: "<hn>", proxy: "<pxy>" }}

        # Get key name eg 'graphite' from 'graphite[....]'
        self.key = metrics[0]['key_'][0:metrics[0]['key_'].find('[')]
        key_len = len(self.key)

        def metrics_filter(m):
            metric_pattern = metric = m['key_'][key_len + 1:-1]
            if not '{h}' in metric_pattern:
                metric_pattern = '{h}.'+metric_pattern
            host = hosts[ int(m['hostid']) ]
            return {
                'host': host['name'],
                'proxy': host['proxy'],
                'metric': metric,
                'metric_pattern': metric_pattern
            }

        # Input:    [ {'key_':'graphite[value]', 'hostid': '1', 'other': ... }, ... ]
        # Output:   [ {'host': 'localhost', 'metric':'value'}, ... ]
        result = list( map(metrics_filter, metrics) )

        logger.debug("{0}:_getMonitored():{1}".format(self.__class__.__name__, result))
        return result

    def _createGraphiteRequest(self, metric):
        """
        Create http request string to Graphite server.

        We can use function in request:
            graphite[metric_name, graphite_func({metric})] will be translate to:
            target=graphite_func(metric_name)
        """

        result = None

        params = list( map(lambda x: x.strip(), metric['metric_pattern'].split(';')) )

        req = params[0].format( h=self._getHostnameForGraphite( metric['host'] ))
        if len(params) > 1:
            req = params[1].format(metric=req)

        req = self.aggregation_function.format(metric=req)
        req = urllib.parse.quote(req)

        result = self.graphite_url.format(req=req)
        logger.debug("{0}:_getGraphiteData(): url:{1}".format(self.__class__.__name__, result))

        return result

    def _getGraphiteData(self):
        """
        Fill self.metrics with data from Graphite
        """

        def getData(metric):
            # Create a request to graphite server for specifiec metric
            url = self._createGraphiteRequest(metric)

            s_time = time.time()
            try:
                # Get data from graphite API
                res = urllib.request.urlopen(url)
                data = yaml.load(res, Loader=yaml.FullLoader)
            except Exception as e:
                # if error, process next metric and print exception
                logger.error('%s', e)
                return #continue
            finally:
                e_time = time.time() - s_time
                # Convert to milliseconds
                e_time = int(e_time * 1000)
                logger.debug("{cn}:_getGraphiteData(): urlopen time {time}ms for {url}".format(cn=self.__class__.__name__, time=e_time, url=url))

            logger.debug("{0}:_getGraphiteData(): data:{1}\n".format(self.__class__.__name__, data))
            # Process data if it not empty
            if len(data) and 'datapoints' in data[0]:
                datapoints = list( filter( lambda d: d[0] != None, data[0]['datapoints'] ))
                logger.debug("{0}:_getGraphiteData(): filter(datapoints):{1}".format(self.__class__.__name__, datapoints))

                if datapoints:
                    # We are only interested in latest datapoint
                    data = datapoints[-1]
                    # Update metric record
                    logger.debug({'value': data[0], 'time': data[1] })
                    metric.update({ 'value': data[0], 'time': data[1] })

        pool = Pool(processes=self.threads)
        try:
            pool.map(getData, self.metrics)
        except Exception as e:
            logger.error('%s', e)
            pass
        finally:
            pool.close()
            pool.join()

    def _main(self):
        """
        Main function of the class.
        """

        # Get zabbix metrics and host
        self.metrics = self._getMetrics()

        # Get graphite data
        self._getGraphiteData()

        # Create zabbix message packet
        msg = []
        for m in self.metrics:
            if 'value' in m:
                metric = '{0}[{1}]'.format(self.key, m['metric'])
                self.proxy_sorter.add_metric(m, metric, m['value'], m['time'])
                # msg.append( ZabbixMetric(m['host'], metric, m['value'], m['time']) )
                if self.debug_mode:
                    print('DEBUG: ({t}) {met} for {h} is {v}\n'.format( met=m['metric'], h=m['host'], v=m['value'], t=m['time'] ))

        if self.debug_mode:
            print('DEBUG: number of metrics is {}'.format(len(self.metrics)))
            self._debugOutput(msg)
        else:
            for proxy in self.proxy_sorter.get_proxies():
                #  TODO --- need dynamic sender config, to reflect changing proxy addresses
                result = ZabbixSender(**(self.zabbix_sender_config({'zabbix_server':proxy}))).send(self.proxy_sorter.get_metrics_for(proxy))
                logger.debug("{cn}:_main: Sending to {p} result: {r}".format(p=proxy, cn=self.__class__.__name__, r=result))

if __name__ == '__main__':

    # define mungers for hostnames
    hostname_mungers = dict([
        ('hostname_default', lambda x: x),
        ('hostname_only',    lambda x: x.split(".")[0])
    ])
    argparser = argparse.ArgumentParser(description="Graphite to Zabbix proxy",
            prog="g2zproxy")

    argparser.add_argument('-v', '--version', action='version', version='%(prog)s 0.2')
    argparser.add_argument('-d', '--debug', action='store_true', help='In debug mode, no data is inserted in Zabbix; it is printed out instead.')
    argparser.add_argument('-z', '--zabbix-url', default='http://localhost',
            help='Specify URL to Zabbix.')
    argparser.add_argument('-zu', '--zabbix-user', default='admin',
            help='Specify zabbix user.')
    argparser.add_argument('-zp', '--zabbix-pass', default='zabbix',
            help='Specify zabbix password.')
    argparser.add_argument('-zs', '--zabbix-server', default=None, help='Specify Zabbix server IP')
    argparser.add_argument('-zr', '--zabbix-port', default=None, help='Specify Zabbix server trapper port')
    argparser.add_argument('-g', '--graphite-url', default='http://localhost',
            help='Specify URL to Graphite.')
    argparser.add_argument('-n', '--hostname-only', action='store_const', default='hostname_default', const='hostname_only', help='Set to have all but the first dot-separated token stripped', dest='hostname_munger')
    argparser.add_argument('-t', '--threads', default=50, type=int,
            help='Number threads to get simultaneously requests to Graphite')
    argparser.add_argument('-a', '--aggregation-function', default='{metric}',
            help='Aggregation function.  Example: timeShift(movingAverage({metric}, "5min"), "+150sec")')
    # argparser.add_argument('-a', '--aggregation-function', default='timeShift(movingAverage({metric}, "5min"), "+150sec")',
    #         help='Aggregation function')

    args = argparser.parse_args()

    # if no arguments - show help
    if len(sys.argv) <= 1:
        argparser.print_help()
        exit()

    # example_host = 'somehost.example.com'

    # print("example hostname: {0}".format(example_host))
    # print("          munged: {0}".format(hostname_mungers[args.hostname_munger](example_host)))

    G2ZProxy(zabbix_url = args.zabbix_url,
             zabbix_user = args.zabbix_user,
             zabbix_pass = args.zabbix_pass,
             zabbix_server = args.zabbix_server,
             zabbix_port = args.zabbix_port,
             graphite_url = args.graphite_url,
             threads = args.threads,
             aggregation_function = args.aggregation_function,
             hostname_munger = hostname_mungers[ args.hostname_munger ],
             debug_mode = args.debug)
