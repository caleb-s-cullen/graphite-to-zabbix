#!/usr/bin/env python

### Dependencies: urllib, py-zabbix, yaml, json

import logging
import sys
import time
import urllib.request
import urllib.parse
import yaml
import json
import pprint
import collections.abc

from multiprocessing.pool import ThreadPool as Pool

try:
    import argparse
except:
    print("You need python 2.7+ or installed argparse module.\n\tpip install argparse")
    exit()

try:
    # from zabbix.api import ZabbixAPI
    from pyzabbix.api import ZabbixAPI
    # from zabbix.sender import ZabbixSender, ZabbixMetric
    from pyzabbix.sender import ZabbixSender, ZabbixMetric
except:
    print("Zabbix module py-zabbix is required.")
    exit()

logging.basicConfig(level = logging.DEBUG, format='%(asctime)s %(message)s', datefmt='%m/%d/%Y %I:%M:%S %p')
logger = logging.getLogger(__name__)

class JSONMetricsSorter(collections.abc.Mapping):
    """
    A class for objects which will track metrics on a per-host basis
    It will generate a JSON data packet for each host

    It stores everything as a hash, the keys being the hostnames.
    The values are hashes, mapping the Zabbix item key onto a value;
      a timestamp will be applied to the JSON payload.  It is problematic to do better.

    """
    # initialization function allows for override of metric name
    def __init__(self, *hostnames, **kwargs):
        self.metric_key = kwargs.get('metric_key', 'imported_metrics')
        self.data = {}
        if len(hostnames) > 0:
            for name in hostnames:
                self.data[name] = {}

    # provide __repr__ for string representation
    def __repr__(self):
        return f"{self._classname()}: metric_key: {self.metric_key} data: {self.data}"

    # provide __sizeof__
    def __sizeof__(self):
        return self.data.__sizeof__() + self.metric_key.__sizeof__()

    # Provide certain private definitions for Mapping conformance
    def __len__(self):
        return len(self.data)

    def __iter__(self):
        yield from self.data

    def __getitem__(self, host):
        return self.data[host]

    # access the metric key
    def get_zabbix_metric_key(self):
        return self.metric_key

    # return a single ZabbixMetric object for the named host
    def get_metrics_for(self, host):
        try:
            return ZabbixMetric( host, self.metric_key, json.dumps( self.data[host] ))
        except KeyError as e:
            raise(e)

    # return a list of ZabbixMetric objects, one for each host referenced
    def get_all_metrics(self):
        return [ ZabbixMetric( host, self.metric_key, json_dumps( metrics )) for host,metrics in self.data.items() ]

    # insert another metric value for a particular host into the sorter
    def add_metric_for(self, host, keyname, value):
        if host not in self.data:
            self.data[host] = {}
        self.data[host][keyname] = value
        return self

class G2ZProxyException(Exception):
    pass

class G2ZProxy(object):
    """
    Proxy between Graphite and Zabbix servers.

    Attributes:
        pattern (str)   Pattern for graphites key in zabbix.
                        Default: graphite*
    """

    def __init__(self, pattern='graphite*',
                 zabbix_url='http://localhost',
                 zabbix_user='admin',
                 zabbix_pass='zabbix',
                 zabbix_server=None,
                 zabbix_port=None,
                 graphite_url='http://localhost',
                 threads=1,
                 aggregation_function='{metric}',
                 hostname_munger=lambda x: x,
                 debug_mode=False):

        self.cn = self.__class__.__name__

        # Takes needed metric from zabbix
        self.pattern = pattern
        self.zabbix_url = zabbix_url
        self.graphite_url = graphite_url + '/render?from=-5minutes&rawData=true&target={req}&format=json'
        self.aggregation_function = aggregation_function
        self.hostname_munger = hostname_munger
        self.zapi = ZabbixAPI(self.zabbix_url, user=zabbix_user, password=zabbix_pass)
        self.threads = threads
        self.debug_mode = debug_mode
        self.json_sorter = JSONMetricsSorter()
        if zabbix_server is not None:
            self.zabbix_sender_config = { 'zabbix_server': zabbix_server }
            if zabbix_port is not None:
                self.zabbix_sender_config['zabbix_port'] = zabbix_port
        else:
            self.zabbix_sender_config = { 'use_config':  True }
        self._main()

    def _debugOutput(self, msg):
        logger.debug("{0}: outputting datastructure instead of sending to Zabbix".format(self.__class__.__name__))
        logger.debug(pprint.pformat(self.json_sorter))
        logger.debug(self.json_sorter.get_all_metrics())

    def _getHostsFromMetrics(self, metrics):
        """
        Get list of unique hosts from metric list.

        Attributes:
          metrics (list)    List of metrics from zabbix
        """

        # Get list of uniq hostid
        hostids = list(set(map(lambda x: int(x['hostid']), metrics)))

        # Get host names by id
        hostids = self.zapi.host.get(hostids=hostids, output=['name'])

        hosts = {}
        for m in hostids:
            hosts.update({ int(m['hostid']): self.hostname_munger(m['name']) })

        logger.debug("{0}:_getHostsFromMetrics(metrics):{1}".format(self.__class__.__name__, hosts))

        return hosts

    def _getMonitoredMetrics(self):
        """
        Return monitored metrics from zabbix
        """

        result = None
        if self.zapi:
            metrics = self.zapi.item.get(
                search = { 'key_': self.pattern },
                searchWildcardsEnabled = True,
                monitored = True,
                output = ['key_', 'hostid'])
            result = metrics

        logger.debug("{0}:_getMonitoredMetrics(metrics):{1}".format(self.__class__.__name__, result))
        return result


    def _getMetrics(self):
        """
        Get metrics from zabbix transform it to list of key, value pairs.
        """

        result = None
        metrics = self._getMonitoredMetrics()
        hosts = self._getHostsFromMetrics(metrics)

        # Get key name eg 'graphite' from 'graphite[....]'
        self.key = metrics[0]['key_'][0:metrics[0]['key_'].find('[')]
        key_len = len(self.key)

        def metrics_filter(m):
            metric_pattern = metric = m['key_'][key_len + 1:-1]
            if not '{h}' in metric_pattern:
                metric_pattern = '{h}.'+metric_pattern
            host = hosts[int(m['hostid'])]
            return {
                'host': host,
                'metric': metric,
                'metric_pattern': metric_pattern
            }

        # Input:    [ {'key_':'graphite[value]', 'hostid': '1', 'other': ... }, ... ]
        # Output:   [ {'host': 'localhost', 'metric':'value'}, ... ]
        result = list( map(metrics_filter, metrics) )

        logger.debug("{0}:_getMonitored():{1}".format(self.__class__.__name__, result))
        return result

    def _createGraphiteRequest(self, metric):
        """
        Create http request string to Graphite server.

        We can use function in request:
            graphite[metric_name, graphite_func({metric})] will be translate to:
            target=graphite_func(metric_name)
        """

        result = None

        params = list( map(lambda x: x.strip(), metric['metric_pattern'].split(';')) )

        req = params[0].format(h=metric['host'])
        if len(params) > 1:
            req = params[1].format(metric=req)

        req = self.aggregation_function.format(metric=req)
        req = urllib.parse.quote(req)

        result = self.graphite_url.format(req=req)
        logger.debug("{0}:_getGraphiteData(): url:{1}".format(self.__class__.__name__, result))

        return result

    def _getGraphiteData(self):
        """
        Fill self.metrics with data from Graphite
        """

        def getData(metric):
            # Create a request to graphite server for specifiec metric
            url = self._createGraphiteRequest(metric)

            s_time = time.time()
            try:
                # Get data from graphite API
                res = urllib.request.urlopen(url)
                data = yaml.load(res, Loader=yaml.FullLoader)
            except Exception as e:
                # if error, process next metric and print exception
                logger.error('%s', e)
                return #continue
            finally:
                e_time = time.time() - s_time
                # Convert to milliseconds
                e_time = int(e_time * 1000)
                logger.debug("{cn}:_getGraphiteData(): urlopen time {time}ms for {url}".format(cn=self.__class__.__name__, time=e_time, url=url))

            logger.debug("{0}:_getGraphiteData(): data:{1}\n".format(self.__class__.__name__, data))
            # Process data if it not empty
            if len(data) and 'datapoints' in data[0]:
                datapoints = list( filter( lambda d: d[0] != None, data[0]['datapoints'] ))
                logger.debug("{0}:_getGraphiteData(): filter(datapoints):{1}".format(self.__class__.__name__, datapoints))

                if datapoints:
                    # We are only interested in latest datapoint
                    data = datapoints[-1]
                    # Update metric record
                    logger.debug({'value': data[0], 'time': data[1] })
                    metric.update({ 'value': data[0], 'time': data[1] })

        pool = Pool(processes=self.threads)
        try:
            pool.map(getData, self.metrics)
        except Exception as e:
            logger.error('%s', e)
            pass
        finally:
            pool.close()
            pool.join()

    def _main(self):
        """
        Main function of the class.
        """

        # Get zabbix metrics and host
        self.metrics = self._getMetrics()

        # Get graphite data
        self._getGraphiteData()

        # Create zabbix message packet
        msg = []
        for m in self.metrics:
            if 'value' in m:
                metric = '{0}[{1}]'.format(self.key, m['metric'])
                self.json_sorter.add_metric_for(m['host'], metric, m['value'], m['time'])
                if self.debug_mode:
                    print('DEBUG: {t} {met} for {h} is {v}\n'.format( met=m['metric'], h=m['host'], v=m['value'], t=m['time'] ))

        if self.debug_mode:
            self._debugOutput(msg)
        else:
            # ZabbixSender(use_config=True).send(msg) # can't use config here, it doesn't look at agent2.conf
            ZabbixSender(**self.zabbix_sender_config).send(self.json_sorter.get_all_metrics) # we can configure this from the cmdline
        print(len(self.metrics))

if __name__ == '__main__':

    # define mungers for hostnames
    hostname_mungers = dict([
        ('hostname_default', lambda x: x),
        ('hostname_only',    lambda x: x.split(".")[0])
    ])
    argparser = argparse.ArgumentParser(description="Graphite to Zabbix proxy",
            prog="g2zproxy")

    argparser.add_argument('-v', '--version', action='version', version='%(prog)s 0.2')
    argparser.add_argument('-d', '--debug', action='store_true', help='In debug mode, no data is inserted in Zabbix; it is printed out instead.')
    argparser.add_argument('-z', '--zabbix-url', default='http://localhost',
            help='Specify URL to Zabbix.')
    argparser.add_argument('-zu', '--zabbix-user', default='admin',
            help='Specify zabbix user.')
    argparser.add_argument('-zp', '--zabbix-pass', default='zabbix',
            help='Specify zabbix password.')
    argparser.add_argument('-zs', '--zabbix-server', default=None, help='Specify Zabbix server IP')
    argparser.add_argument('-zr', '--zabbix-port', default=None, help='Specify Zabbix server trapper port')
    argparser.add_argument('-g', '--graphite-url', default='http://localhost',
            help='Specify URL to Graphite.')
    argparser.add_argument('-n', '--hostname-only', action='store_const', default='hostname_default', const='hostname_only', help='Set to have all but the first dot-separated token stripped', dest='hostname_munger')
    argparser.add_argument('-t', '--threads', default=50, type=int,
            help='Number threads to get simultaneously requests to Graphite')
    argparser.add_argument('-a', '--aggregation-function', default='{metric}',
            help='Aggregation function.  Example: timeShift(movingAverage({metric}, "5min"), "+150sec")')
    # argparser.add_argument('-a', '--aggregation-function', default='timeShift(movingAverage({metric}, "5min"), "+150sec")',
    #         help='Aggregation function')

    args = argparser.parse_args()

    # if no arguments - show help
    if len(sys.argv) <= 1:
        argparser.print_help()
        exit()

    # example_host = 'somehost.example.com'

    # print("example hostname: {0}".format(example_host))
    # print("          munged: {0}".format(hostname_mungers[args.hostname_munger](example_host)))

    G2ZProxy(zabbix_url = args.zabbix_url,
             zabbix_user = args.zabbix_user,
             zabbix_pass = args.zabbix_pass,
             zabbix_server = args.zabbix_server,
             zabbix_port = args.zabbix_port,
             graphite_url = args.graphite_url,
             threads = args.threads,
             aggregation_function = args.aggregation_function,
             hostname_munger = hostname_mungers[ args.hostname_munger ],
             debug_mode = args.debug)
